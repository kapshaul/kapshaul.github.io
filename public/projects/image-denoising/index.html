<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>EM Algorithm for CT Image Denoising | Yong-Hwan Lee</title>
<meta name="keywords" content="Statistical Estimation, Non-Parametric Estimation, MLE, CT Imaging, Image Denoising">
<meta name="description" content="This study was carried out as a project at Oregon State University.">
<meta name="author" content="Yong-Hwan Lee,&thinsp;Tony Storey">
<link rel="canonical" href="http://localhost:1313/projects/image-denoising/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6cf4a8fa527330d9574f36d8d000fdaf90ca838ff09ab72fc27d3cb7ca1ddc5.css" integrity="sha256-1s9Kj6UnMw2VdPNtjQAP2vkMqDj/Caty/CfTy3yh3cU=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/projects/image-denoising/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="EM Algorithm for CT Image Denoising" />
<meta property="og:description" content="This study was carried out as a project at Oregon State University." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/projects/image-denoising/" />
<meta property="og:image" content="http://localhost:1313/image.png" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2019-12-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-03-20T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/image.png" />
<meta name="twitter:title" content="EM Algorithm for CT Image Denoising"/>
<meta name="twitter:description" content="This study was carried out as a project at Oregon State University."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "http://localhost:1313/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "EM Algorithm for CT Image Denoising",
      "item": "http://localhost:1313/projects/image-denoising/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "EM Algorithm for CT Image Denoising",
  "name": "EM Algorithm for CT Image Denoising",
  "description": "This study was carried out as a project at Oregon State University.",
  "keywords": [
    "Statistical Estimation", "Non-Parametric Estimation", "MLE", "CT Imaging", "Image Denoising"
  ],
  "articleBody": " Download Report Code Abstract This project simulates the Expectation Maximization (EM) algorithm for removing Poisson noise from medical images. The EM algorithm is particularly useful in this context because it allows for the estimation of the underlying image by iteratively maximizing the likelihood function, which accounts for the statistical nature of Poisson noise. Given the quantum nature of particles and their discrete arrival times, Poisson noise often manifests in medical imaging, especially in modalities like X-ray Computed Tomography (CT). This noise can lead to significant artifacts in the reconstructed images, which might result in diagnostic inaccuracies.\nFigure 1: Top - Illustration of a CT scan procedure; Bottom - Denoising a CT image\nTo mitigate these issues, the EM algorithm is applied as it effectively separates the noise from the actual signal in the image data. By modeling the image acquisition process and noise characteristics, the algorithm iteratively refines the image estimate, ultimately converging on a solution that minimizes the impact of noise.\nFind more details from the report: PDF\nProblem Formulation 1. Observation The distribution of $N_{ij}$ is given by,\n$$ N_{ij} \\sim Pois(a_{ij} \\lambda_j) $$\nHere, $Pois$ denotes the Poisson distribution with parameter $\\lambda$. Consider a model matrix $A$, where $A = (a_{ij})$ $i = 1, \\dots, n$ $j = 1, \\dots, m$.\nThen, the observations $Y_{i=1,…n}$ can be written as below,\n$$ Y_i = \\sum_{j=1}^m N_{ij} \\sim \\sum_{j=1}^m Pois(a_{ij} \\lambda_j) $$\n2. 3x3 cross section of voxel model Each pixel represents the absorption coefficient. Below are examples of voxel models,\n| *--------------------* | | y3---\\ | | | | | | ---/ | p1 | p2 | p3 | | - *--------------------* - | y2---\\ | | | | | | ---/ | p4 | p5 | p6 | | - *--------------------* - | y1---\\ | | | | | | ---/ | p7 | p8 | p9 | | | *--------------------* | -------|------|------- y9 y10 y11 || || || \\/ \\/ \\/ *--------------------* | | | | | p1 | p2 | p3 | *--------------------* | | | | | p4 | p5 | p6 | *--------------------* | | | | | p7 | p8 | p9 | *--------------------* -------|------|------- EM Algorithm 1. Likelihood function For the observations, the likelihood function can be written as,\n$$ L(N_{ij})_ {ij}(\\lambda) = \\prod_i^n\\prod_j^m e^{a_{ij} \\lambda_j} \\frac{(\\lambda_j a_{ij})^{N_{ij}}}{N_{ij}!} $$\nThen, log-likelihood function can be below,\n$$ l(N_{ij})_ {ij}(\\lambda) = \\sum_i^n \\sum_j^m (-\\lambda_j a_{ij} + N_{ij}\\log{(\\lambda_j a_{ij})} -\\log{(N_{ij}!)}) $$\nLooking at the derivative of the log-likelihood with resprect to $\\lambda_j$ we obtain\n$$ \\frac{d}{d \\lambda_{j}}E[l_{(N_{ij})_ {ij}} | (Y_{i})_ {i}] = \\sum_{i=1}^n -a_{ij} + \\frac{1}{\\lambda_j} E[(N_{ij})_ {ij} | (Y_{i})_ {i}] \\quad \\forall j=1,…,m $$\n2. Parameter Update Lemma. Let $X_1$, $X_2$ be independent Poisson distributions with\n$$ X_1 \\sim Pois(\\lambda_1) $$\n$$ X_2 \\sim Pois(\\lambda_2) $$\nThen, $X_1|(X_1 + X_2) \\sim B(X_1 + X_2, \\frac{\\lambda_1}{\\lambda_1+\\lambda_2})$.\nBy taking $X_1 = N_{ij}$ and $X_2 = Y_i − N_{ij}$, we find $N_{ij} |Y_i \\sim B(Y_i, \\frac{a_{ij}\\lambda_j}{\\sum_{k=1}^m a_{ik}\\lambda_k})$\nBecause the expectation of a Binomial distribution with parameters $n$, $p$ is $np$ we have,\n$$ E[N_{ij}|Y_i] = \\frac{Y_i a_{ij}\\lambda_j}{\\sum_{k=1}^m a_{ik}\\lambda_k} $$\nTherefore,\n$$ \\frac{d}{d \\lambda_{j}}E[l_{(N_{ij})_ {ij}} | (Y_{i})_ {i}] = \\sum_{i=1}^n -a_{ij} + \\frac{1}{\\lambda_j} \\frac{Y_i a_{ij}\\lambda_{j}^{old}}{\\sum_{k=1}^{m} a_{ik}\\lambda_{k}^{old}} \\quad \\forall j=1,…,m $$\nSetting the derivative to 0 to find a possible maximum gives,\n$$ 0 = \\sum_{i=1}^n -a_{ij} + \\frac{1}{\\lambda_j} \\frac{Y_i a_{ij}\\lambda_{j}^{old}}{\\sum_{k=1}^{m} a_{ik}\\lambda_{k}^{old}} $$\nSolving for all $\\lambda_j$ gives,\n$$ \\lambda_j = \\frac{\\lambda_{j}^{old}}{\\sum_{i=1}^{n} a_{ij}} \\sum_{i=1}^n \\frac{Y_i a_{ij}}{\\sum_{k=1}^{m} a_{ik}\\lambda_{k}^{old}} $$\n3. EM Algorithm MATLAB code function X_new = EM_algorithm(A, y, X) n = length(X); m = length(y); % Starting EM Algorithm for j = 1:n for i = 1:m den1 = A*X; % Compute the probability prob(i) = y(i)*A(i,j)/den1(i); end % E step to copute expectation expectation(j) = sum(prob); den2(j) = sum(A(:,j)); % M step to maximize likelihood X_new(j) = X(j)/den2(j)*expectation(j); end end 4. Result The Expectation Maximization (EM) algorithm was implemented in MATLAB to reduce noise and estimate the 9 parameters from a 3x3 pixel matrix. To validate its performance, 10000 Monte Carlo simulations were conducted, and the resulting EM estimates were used to recover the underlying data.\nAs shown in Figure 2, the EM algorithm exhibited a monotonically increasing likelihood as it converged toward a stable solution.\nThe Cramér-Rao Lower Bound (CRLB) was used as a benchmark to assess the efficiency of the mean squared error (MSE) for each parameter. To further evaluate performance, the signal gain was varied from 0.1 to 10, with both the CRLB and MSE as illustrated in Figure 3.\nFigure 2: Log-likelihood maximization progress over iterations\nFigure 3: MSE comparison with CRLB\nImplementation To implement the code, follow these steps:\nClone the repository from GitHub. Run the main.m file to complete the EM algorithm and estimate the body model matrix coefficients. Reference [1] C. F. van Oosten, “The EM-algorithm for Poisson data,” Bachelor’s thesis, Mathematical Institute, Leiden University, Leiden, The Netherlands, Aug. 2014.\n",
  "wordCount" : "810",
  "inLanguage": "en",
  "image":"http://localhost:1313/image.png","datePublished": "2019-12-10T00:00:00Z",
  "dateModified": "2025-03-20T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Yong-Hwan Lee"
  }, {
    "@type": "Person",
    "name": "Tony Storey"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/projects/image-denoising/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yong-Hwan Lee",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class=" dark" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Yong-Hwan Lee">
                <img src="http://localhost:1313/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Yong-Hwan Lee</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/studies/" title="Studies">
                    <span>Studies</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      EM Algorithm for CT Image Denoising
    </h1>
    <div class="post-meta"><span title='2019-12-10 00:00:00 +0000 UTC'>December 2019</span>&nbsp;&middot;&nbsp;Yong-Hwan Lee,&thinsp;Tony Storey

</div>
  </header> 
  <div class="post-content"><hr>
<h5 id="download">Download</h5>
<ul>
<li><a href="paper.pdf">Report</a></li>
<li><a href="https://github.com/kapshaul/CT-medical-imaging" target="_blank">Code</a></li>
</ul>
<hr>
<h5 id="abstract">Abstract</h5>
<p>This project simulates the Expectation Maximization (EM) algorithm for removing Poisson noise from medical images. The EM algorithm is particularly useful in this context because it allows for the estimation of the underlying image by iteratively maximizing the likelihood function, which accounts for the statistical nature of Poisson noise. Given the quantum nature of particles and their discrete arrival times, Poisson noise often manifests in medical imaging, especially in modalities like X-ray Computed Tomography (CT). This noise can lead to significant artifacts in the reconstructed images, which might result in diagnostic inaccuracies.</p>
<br>
<div align="center">
<p><img src="CT%20scan.jpg" width="400">     
<img src="image.png" width="400"></p>
<p><strong>Figure 1</strong>: Top - Illustration of a CT scan procedure; Bottom - Denoising a CT image</p>
</div>
<br>
<p>To mitigate these issues, the EM algorithm is applied as it effectively separates the noise from the actual signal in the image data. By modeling the image acquisition process and noise characteristics, the algorithm iteratively refines the image estimate, ultimately converging on a solution that minimizes the impact of noise.</p>
<p>Find more details from the report: <a href="paper.pdf">PDF</a></p>
<hr>
<h5 id="problem-formulation">Problem Formulation</h5>
<h5 id="1-observation">1. Observation</h5>
<p>The distribution of $N_{ij}$ is given by,</p>
<p>$$
N_{ij} \sim Pois(a_{ij} \lambda_j)
$$</p>
<p>Here, $Pois$ denotes the Poisson distribution with parameter $\lambda$. Consider a model matrix $A$, where $A = (a_{ij})$ $i = 1, \dots, n$ $j = 1, \dots, m$.</p>
<p>Then, the observations $Y_{i=1,&hellip;n}$ can be written as below,</p>
<p>$$
Y_i = \sum_{j=1}^m N_{ij} \sim \sum_{j=1}^m Pois(a_{ij} \lambda_j)
$$</p>
<h5 id="2-3x3-cross-section-of-voxel-model">2. 3x3 cross section of voxel model</h5>
<p>Each pixel represents the absorption coefficient. Below are examples of voxel models,</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>                                |        *--------------------*       |  
</span></span><span style="display:flex;"><span>                                | y3---\ |      |      |      |       | 
</span></span><span style="display:flex;"><span>                                |   ---/ |  p1  |  p2  |  p3  |       | 
</span></span><span style="display:flex;"><span>                                -        *--------------------*       - 
</span></span><span style="display:flex;"><span>                                | y2---\ |      |      |      |       | 
</span></span><span style="display:flex;"><span>                                |   ---/ |  p4  |  p5  |  p6  |       | 
</span></span><span style="display:flex;"><span>                                -        *--------------------*       - 
</span></span><span style="display:flex;"><span>                                | y1---\ |      |      |      |       | 
</span></span><span style="display:flex;"><span>                                |   ---/ |  p7  |  p8  |  p9  |       | 
</span></span><span style="display:flex;"><span>                                |        *--------------------*       |  
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>                                         -------|------|-------
</span></span><span style="display:flex;"><span>                                            y9     y10    y11
</span></span><span style="display:flex;"><span>                                            ||     ||     ||
</span></span><span style="display:flex;"><span>                                            \/     \/     \/
</span></span><span style="display:flex;"><span>                                         *--------------------*          
</span></span><span style="display:flex;"><span>                                         |      |      |      |        
</span></span><span style="display:flex;"><span>                                         |  p1  |  p2  |  p3  |        
</span></span><span style="display:flex;"><span>                                         *--------------------*        
</span></span><span style="display:flex;"><span>                                         |      |      |      |        
</span></span><span style="display:flex;"><span>                                         |  p4  |  p5  |  p6  |        
</span></span><span style="display:flex;"><span>                                         *--------------------*        
</span></span><span style="display:flex;"><span>                                         |      |      |      |        
</span></span><span style="display:flex;"><span>                                         |  p7  |  p8  |  p9  |        
</span></span><span style="display:flex;"><span>                                         *--------------------*         
</span></span><span style="display:flex;"><span>                               
</span></span><span style="display:flex;"><span>                                         -------|------|------- 
</span></span></code></pre></div><hr>
<h5 id="em-algorithm">EM Algorithm</h5>
<h5 id="1-likelihood-function">1. Likelihood function</h5>
<p>For the observations, the likelihood function can be written as,</p>
<p>$$
L(N_{ij})_ {ij}(\lambda) = \prod_i^n\prod_j^m e^{a_{ij} \lambda_j} \frac{(\lambda_j a_{ij})^{N_{ij}}}{N_{ij}!}
$$</p>
<p>Then, log-likelihood function can be below,</p>
<p>$$
l(N_{ij})_ {ij}(\lambda) = \sum_i^n \sum_j^m (-\lambda_j a_{ij} + N_{ij}\log{(\lambda_j a_{ij})} -\log{(N_{ij}!)})
$$</p>
<p>Looking at the derivative of the log-likelihood with resprect to $\lambda_j$ we obtain</p>
<p>$$
\frac{d}{d \lambda_{j}}E[l_{(N_{ij})_ {ij}} | (Y_{i})_ {i}] = \sum_{i=1}^n -a_{ij} + \frac{1}{\lambda_j} E[(N_{ij})_ {ij} | (Y_{i})_ {i}] \quad \forall j=1,&hellip;,m
$$</p>
<h5 id="2-parameter-update">2. Parameter Update</h5>
<p><em><strong>Lemma</strong></em>. Let $X_1$, $X_2$ be independent Poisson distributions with</p>
<p>$$
X_1 \sim Pois(\lambda_1)
$$</p>
<p>$$
X_2 \sim Pois(\lambda_2)
$$</p>
<p>Then, $X_1|(X_1 + X_2) \sim B(X_1 + X_2, \frac{\lambda_1}{\lambda_1+\lambda_2})$.</p>
<br>
<p>By taking $X_1 = N_{ij}$ and $X_2 = Y_i − N_{ij}$, we find $N_{ij} |Y_i \sim B(Y_i, \frac{a_{ij}\lambda_j}{\sum_{k=1}^m a_{ik}\lambda_k})$</p>
<p>Because the expectation of a Binomial distribution with parameters $n$, $p$ is $np$ we have,</p>
<p>$$
E[N_{ij}|Y_i] = \frac{Y_i a_{ij}\lambda_j}{\sum_{k=1}^m a_{ik}\lambda_k}
$$</p>
<p>Therefore,</p>
<p>$$
\frac{d}{d \lambda_{j}}E[l_{(N_{ij})_ {ij}} | (Y_{i})_ {i}] = \sum_{i=1}^n -a_{ij} + \frac{1}{\lambda_j} \frac{Y_i a_{ij}\lambda_{j}^{old}}{\sum_{k=1}^{m} a_{ik}\lambda_{k}^{old}} \quad \forall j=1,&hellip;,m
$$</p>
<p>Setting the derivative to 0 to find a possible maximum gives,</p>
<p>$$
0 = \sum_{i=1}^n -a_{ij} + \frac{1}{\lambda_j} \frac{Y_i a_{ij}\lambda_{j}^{old}}{\sum_{k=1}^{m} a_{ik}\lambda_{k}^{old}}
$$</p>
<p>Solving for all $\lambda_j$ gives,</p>
<p>$$
\lambda_j = \frac{\lambda_{j}^{old}}{\sum_{i=1}^{n} a_{ij}} \sum_{i=1}^n \frac{Y_i a_{ij}}{\sum_{k=1}^{m} a_{ik}\lambda_{k}^{old}}
$$</p>
<h5 id="3-em-algorithm-matlab-code">3. EM Algorithm MATLAB code</h5>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-matlab" data-lang="matlab"><span style="display:flex;"><span><span style="color:#00a">function</span><span style="color:#bbb"> </span>X_new =<span style="color:#bbb"> </span><span style="color:#0a0">EM_algorithm</span>(A, y, X)<span style="color:#bbb">    
</span></span></span><span style="display:flex;"><span><span style="color:#bbb">    </span>n = <span style="color:#0aa">length</span>(X);
</span></span><span style="display:flex;"><span>    m = <span style="color:#0aa">length</span>(y);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#aaa;font-style:italic">% Starting EM Algorithm</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a">for</span> <span style="color:#0aa">j</span> = <span style="color:#099">1</span>:n
</span></span><span style="display:flex;"><span>        <span style="color:#00a">for</span> <span style="color:#0aa">i</span> = <span style="color:#099">1</span>:m
</span></span><span style="display:flex;"><span>            den1 = A*X;
</span></span><span style="display:flex;"><span>            <span style="color:#aaa;font-style:italic">% Compute the probability</span>
</span></span><span style="display:flex;"><span>            prob(<span style="color:#0aa">i</span>) = y(<span style="color:#0aa">i</span>)*A(<span style="color:#0aa">i</span>,<span style="color:#0aa">j</span>)/den1(<span style="color:#0aa">i</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#00a">end</span>
</span></span><span style="display:flex;"><span>        <span style="color:#aaa;font-style:italic">% E step to copute expectation</span>
</span></span><span style="display:flex;"><span>        expectation(<span style="color:#0aa">j</span>) = sum(prob);
</span></span><span style="display:flex;"><span>        den2(<span style="color:#0aa">j</span>) = sum(A(:,<span style="color:#0aa">j</span>));
</span></span><span style="display:flex;"><span>        <span style="color:#aaa;font-style:italic">% M step to maximize likelihood</span>
</span></span><span style="display:flex;"><span>        X_new(<span style="color:#0aa">j</span>) = X(<span style="color:#0aa">j</span>)/den2(<span style="color:#0aa">j</span>)*expectation(<span style="color:#0aa">j</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#00a">end</span>
</span></span><span style="display:flex;"><span><span style="color:#00a">end</span>
</span></span></code></pre></div><h5 id="4-result">4. Result</h5>
<p>The Expectation Maximization (EM) algorithm was implemented in MATLAB to reduce noise and estimate the 9 parameters from a 3x3 pixel matrix. To validate its performance, 10000 Monte Carlo simulations were conducted, and the resulting EM estimates were used to recover the underlying data.</p>
<p>As shown in Figure 2, the EM algorithm exhibited a monotonically increasing likelihood as it converged toward a stable solution.</p>
<p>The Cramér-Rao Lower Bound (CRLB) was used as a benchmark to assess the efficiency of the mean squared error (MSE) for each parameter. To further evaluate performance, the signal gain was varied from 0.1 to 10, with both the CRLB and MSE as illustrated in Figure 3.</p>
<br>
<div align="center">
<img src="MLE.jpg" width="500">
<p><strong>Figure 2</strong>: Log-likelihood maximization progress over iterations</p>
</div>
<br>
<div align="center">
<img src="MSE.png" width="500">
<p><strong>Figure 3</strong>: MSE comparison with CRLB</p>
</div>
<hr>
<h5 id="implementation">Implementation</h5>
<p>To implement the code, follow these steps:</p>
<ol>
<li>Clone the repository from <a href="https://github.com/kapshaul/CT-medical-imaging" target="_blank">GitHub</a>.</li>
<li>Run the <code>main.m</code> file to complete the EM algorithm and estimate the body model matrix coefficients.</li>
</ol>
<hr>
<h5 id="reference">Reference</h5>
<p>[1] C. F. van Oosten, &ldquo;The EM-algorithm for Poisson data,&rdquo; Bachelor&rsquo;s thesis, Mathematical Institute, Leiden University, Leiden, The Netherlands, Aug. 2014.</p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/statistical-estimation/">Statistical Estimation</a></li>
      <li><a href="http://localhost:1313/tags/non-parametric-estimation/">Non-Parametric Estimation</a></li>
      <li><a href="http://localhost:1313/tags/mle/">MLE</a></li>
      <li><a href="http://localhost:1313/tags/ct-imaging/">CT Imaging</a></li>
      <li><a href="http://localhost:1313/tags/image-denoising/">Image Denoising</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="http://localhost:1313/">Yong-Hwan Lee</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
