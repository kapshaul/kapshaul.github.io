---
title: "LLM Fine-Tunning with GRPO (On Process)" 
date: 2000-01-01
lastmod: 2000-01-01
tags: ["LLM", "Quantization", "Fine-Tunning", "Reinforcement Learning"]
author: ["Yong-Hwan Lee"]
description: "This study was carried out as a personal project." 
summary: "Fine-tuning large language models (LLMs) using Group Relative Policy Optimization (GRPO), an innovative reinforcement learning method introduced by DeepSeek R1. The proposed approach involves training AI models via reinforcement learning (RL), with outputs distilled from advanced reference LLMs." 
cover:
    image: "image.jpeg"
    alt: "LLM Fine-Tunning with GRPO"
    relative: false

---

---

##### On Process

As a personal project, Iâ€™m currently exploring the cutting edge of AI by fine-tuning large language models with Group Relative Policy Optimization (GRPO), an innovative reinforcement learning approach introduced by DeepSeek R1. This ongoing work aims to distill the strengths of advanced reference LLMs, pushing the boundaries of model alignment and performance.
